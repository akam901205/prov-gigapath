#!/usr/bin/env python3
"""
Test End-to-End Pipeline Consistency
Verify that all components use whitened embeddings consistently
"""
import numpy as np
import pickle
from sklearn.preprocessing import normalize
from sklearn.metrics.pairwise import cosine_similarity

def test_pipeline_consistency():
    """Test that the entire pipeline uses whitened embeddings consistently"""
    
    print("ðŸ§ª TESTING END-TO-END PIPELINE CONSISTENCY")
    print("=" * 70)
    
    # Load all required files
    print("ðŸ“‚ Loading all pipeline components...")
    
    # 1. Main cache
    with open("/workspace/embeddings_cache_PROTOTYPE_WHITENED.pkl", 'rb') as f:
        cache = pickle.load(f)
    
    whitened_features = np.array(cache['combined']['features'])
    labels = cache['combined']['labels']
    datasets = cache['combined']['datasets'] 
    filenames = cache['combined']['filenames']
    coordinates = cache['combined']['coordinates']
    
    # 2. Whitening transform
    source_mean = cache['whitening_transform']['source_mean']
    whitening_matrix = cache['whitening_transform']['whitening_matrix']
    
    # 3. Class prototypes
    benign_prototype = cache['class_prototypes']['benign']
    malignant_prototype = cache['class_prototypes']['malignant']
    
    print(f"âœ… Loaded cache: {len(whitened_features)} whitened embeddings")
    print(f"âœ… Whitening transform: {whitening_matrix.shape}")
    print(f"âœ… Coordinates: UMAP{coordinates['umap'].shape}, t-SNE{coordinates['tsne'].shape}, PCA{coordinates['pca'].shape}")
    print(f"âœ… Prototypes: benign({np.linalg.norm(benign_prototype):.6f}), malignant({np.linalg.norm(malignant_prototype):.6f})")
    
    # Test consistency on specific samples
    test_indices = [200, 201, 0, 1]  # b001, b002, iv001, iv002
    
    print(f"\nðŸ”¬ Testing consistency on sample images...")
    
    for idx in test_indices:
        if idx >= len(filenames):
            continue
            
        filename = filenames[idx]
        true_label = labels[idx]
        whitened_embedding = whitened_features[idx]
        
        print(f"\n--- Testing {filename} (true: {true_label}) ---")
        
        # 1. Test prototype prediction
        cos_benign = np.dot(whitened_embedding, benign_prototype)
        cos_malignant = np.dot(whitened_embedding, malignant_prototype)
        proto_pred = 'malignant' if cos_malignant > cos_benign else 'benign'
        
        print(f"   ðŸŽ¯ Prototype: {proto_pred} (cos_b={cos_benign:+.6f}, cos_m={cos_malignant:+.6f})")
        
        # 2. Test similarity against other samples
        similarities = cosine_similarity([whitened_embedding], whitened_features)[0]
        similarities[idx] = -1  # Exclude self
        top_match_idx = np.argmax(similarities)
        top_match_label = labels[top_match_idx]
        top_similarity = similarities[top_match_idx]
        
        print(f"   ðŸ” Top similarity: {filenames[top_match_idx]} ({top_match_label}) sim={top_similarity:.6f}")
        
        # 3. Test coordinate position
        umap_pos = coordinates['umap'][idx]
        tsne_pos = coordinates['tsne'][idx] 
        pca_pos = coordinates['pca'][idx]
        
        print(f"   ðŸ“Š UMAP: ({umap_pos[0]:+.3f}, {umap_pos[1]:+.3f})")
        print(f"   ðŸ“ˆ t-SNE: ({tsne_pos[0]:+.3f}, {tsne_pos[1]:+.3f})")
        print(f"   ðŸ“ PCA: ({pca_pos[0]:+.6f}, {pca_pos[1]:+.6f})")
        
        # 4. Check if embedding is properly normalized
        embedding_norm = np.linalg.norm(whitened_embedding)
        print(f"   âœ… Embedding L2 norm: {embedding_norm:.6f}")
        
        # 5. Consistency check
        expected_pred = 'malignant' if true_label in ['malignant', 'invasive', 'insitu'] else 'benign'
        proto_correct = proto_pred == expected_pred
        
        status = "âœ… CONSISTENT" if proto_correct else "âŒ INCONSISTENT"
        print(f"   {status}: Prototype prediction matches expected")
    
    # Test whitening transform application
    print(f"\nðŸ”§ Testing whitening transform application...")
    
    # Take a sample raw embedding (simulate uploaded image)
    test_raw = np.random.randn(1536) * 100  # Simulate raw GigaPath output
    
    # Apply whitening transform
    centered = test_raw.reshape(1, -1) - source_mean
    whitened = centered @ whitening_matrix.T
    l2_normalized = normalize(whitened, norm='l2')[0]
    
    print(f"   Raw features norm: {np.linalg.norm(test_raw):.3f}")
    print(f"   Whitened L2 norm: {np.linalg.norm(l2_normalized):.6f}")
    
    # Test prototype prediction on new sample
    cos_b_new = np.dot(l2_normalized, benign_prototype)
    cos_m_new = np.dot(l2_normalized, malignant_prototype)
    new_pred = 'malignant' if cos_m_new > cos_b_new else 'benign'
    
    print(f"   New sample prediction: {new_pred} (cos_b={cos_b_new:+.6f}, cos_m={cos_m_new:+.6f})")
    
    print(f"\nâœ… END-TO-END PIPELINE CONSISTENCY VERIFIED!")
    print(f"   - Whitened embeddings: âœ… Consistent")
    print(f"   - Coordinate space: âœ… Consistent") 
    print(f"   - Prototype predictions: âœ… Consistent")
    print(f"   - Transform application: âœ… Working")
    
    return True

if __name__ == "__main__":
    test_pipeline_consistency()