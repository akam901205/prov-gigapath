"""
Complete Preprocessing Pipeline for Pathology Images
Implements the full 7-stage pipeline:
1. Scale normalization (Œºm/pixel standardization)
2. Tissue masking (background removal)
3. H&E stain normalization
4. Resize to 224x224
5. ImageNet normalization
6. GigaPath feature extraction
7. L2 normalization for classification
"""

import numpy as np
import cv2
from PIL import Image, ImageFilter
from sklearn.preprocessing import normalize
import torch
from torchvision import transforms
from typing import Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

try:
    from staintools import StainNormalizer, LuminosityStandardizer
    STAIN_TOOLS_AVAILABLE = True
    print("‚úÖ staintools available")
except ImportError:
    STAIN_TOOLS_AVAILABLE = False
    print("‚ö†Ô∏è staintools not available - stain normalization will be skipped")
except Exception as e:
    STAIN_TOOLS_AVAILABLE = False
    print(f"‚ö†Ô∏è staintools import error: {e} - stain normalization will be skipped")

# Dataset metadata for scale normalization
DATASET_METADATA = {
    'bach': {
        'magnification': '200x',
        'um_per_pixel': 0.5,  # Typical for BACH dataset
        'scanner': 'Aperio',
        'institution': 'University of Barcelona'
    },
    'breakhis': {
        'magnification': '200x', 
        'um_per_pixel': 0.467,  # Typical for BreakHis dataset
        'scanner': 'Olympus BX-50',
        'institution': 'P&D Laboratory'
    }
}

# Target scale for normalization
TARGET_UM_PER_PIXEL = 0.5

class PathologyPreprocessor:
    def __init__(self, target_um_per_pixel: float = TARGET_UM_PER_PIXEL):
        self.target_um_per_pixel = target_um_per_pixel
        self.stain_normalizer = None
        self.reference_image = None
        
        # Initialize stain normalizer if available
        if STAIN_TOOLS_AVAILABLE:
            self._setup_stain_normalizer()
    
    def _setup_stain_normalizer(self):
        """Setup H&E stain normalizer with reference image"""
        try:
            self.stain_normalizer = StainNormalizer(method='macenko')
            # Use a standard H&E reference - could be improved with dataset-specific reference
            print("üé® Stain normalizer initialized (Macenko method)")
        except Exception as e:
            print(f"‚ö†Ô∏è Stain normalizer setup failed: {e}")
            self.stain_normalizer = None
    
    def set_stain_reference(self, reference_image: np.ndarray):
        """Set reference image for stain normalization"""
        if self.stain_normalizer and STAIN_TOOLS_AVAILABLE:
            try:
                # Ensure reference is RGB uint8
                if reference_image.dtype != np.uint8:
                    reference_image = (reference_image * 255).astype(np.uint8)
                
                self.stain_normalizer.fit(reference_image)
                self.reference_image = reference_image
                print("üé® Stain reference image set")
            except Exception as e:
                print(f"‚ö†Ô∏è Failed to set stain reference: {e}")
    
    def scale_normalize(self, image: Image.Image, source_um_per_pixel: float) -> Image.Image:
        """
        Step 1: Scale normalization to fix physical dimensions
        """
        if source_um_per_pixel == self.target_um_per_pixel:
            return image  # No scaling needed
        
        # Calculate scaling factor
        scale_factor = source_um_per_pixel / self.target_um_per_pixel
        
        # Get current size
        width, height = image.size
        
        # Calculate new size maintaining aspect ratio
        new_width = int(width * scale_factor)
        new_height = int(height * scale_factor)
        
        # Resize to maintain physical scale
        scaled_image = image.resize((new_width, new_height), Image.LANCZOS)
        
        print(f"üìè Scale normalized: {source_um_per_pixel:.3f} ‚Üí {self.target_um_per_pixel:.3f} Œºm/pixel (factor: {scale_factor:.3f})")
        return scaled_image
    
    def tissue_mask(self, image: Image.Image) -> Tuple[Image.Image, np.ndarray]:
        """
        Step 2: Tissue masking to remove background
        """
        # Convert to numpy array for processing
        img_array = np.array(image)
        
        # Convert to HSV for better tissue segmentation
        hsv = cv2.cvtColor(img_array, cv2.COLOR_RGB2HSV)
        
        # Create tissue mask - exclude very light (background) areas
        # Adjust thresholds based on typical H&E staining
        lower_tissue = np.array([0, 20, 20])    # Min saturation and value for tissue
        upper_tissue = np.array([180, 255, 240])  # Exclude very bright areas
        
        mask = cv2.inRange(hsv, lower_tissue, upper_tissue)
        
        # Morphological operations to clean up mask
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
        
        # Apply mask to image
        masked_array = img_array.copy()
        masked_array[mask == 0] = [255, 255, 255]  # Set background to white
        
        masked_image = Image.fromarray(masked_array)
        
        tissue_percentage = (mask > 0).sum() / mask.size * 100
        print(f"üî¨ Tissue mask applied: {tissue_percentage:.1f}% tissue content")
        
        return masked_image, mask
    
    def stain_normalize(self, image: Image.Image) -> Image.Image:
        """
        Step 3: H&E stain normalization
        """
        if not STAIN_TOOLS_AVAILABLE or not self.stain_normalizer:
            print("‚ö†Ô∏è Stain normalization skipped - staintools not available")
            return image
        
        try:
            # Convert PIL to numpy
            img_array = np.array(image)
            
            # Ensure uint8 format
            if img_array.dtype != np.uint8:
                img_array = (img_array * 255).astype(np.uint8)
            
            # Apply stain normalization
            normalized_array = self.stain_normalizer.transform(img_array)
            
            # Convert back to PIL
            normalized_image = Image.fromarray(normalized_array)
            
            print("üé® H&E stain normalization applied (Macenko)")
            return normalized_image
            
        except Exception as e:
            print(f"‚ö†Ô∏è Stain normalization failed: {e}, using original image")
            return image
    
    def resize_to_model_input(self, image: Image.Image) -> Image.Image:
        """
        Step 4: Resize to model input size (224x224)
        """
        resized = image.resize((224, 224), Image.LANCZOS)
        print("üìê Resized to 224x224 for GigaPath input")
        return resized
    
    def imagenet_normalize(self, image: Image.Image) -> torch.Tensor:
        """
        Step 5: ImageNet normalization for GigaPath
        """
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        tensor = transform(image)
        print("üéØ ImageNet normalization applied")
        return tensor
    
    def extract_gigapath_features(self, tensor: torch.Tensor, gigapath_model) -> np.ndarray:
        """
        Step 6: GigaPath feature extraction
        """
        device = next(gigapath_model.parameters()).device
        tensor = tensor.unsqueeze(0).to(device)
        
        with torch.no_grad():
            features = gigapath_model(tensor)
            features = features.cpu().numpy().flatten()
        
        print(f"üß† GigaPath features extracted: {features.shape}")
        return features
    
    def l2_normalize_features(self, features: np.ndarray) -> np.ndarray:
        """
        Step 7: L2 normalization for classification
        """
        l2_features = normalize([features], norm='l2')[0]
        print("üìä L2 normalization applied for classification")
        return l2_features
    
    def complete_pipeline(self, 
                         image: Image.Image, 
                         gigapath_model,
                         source_um_per_pixel: float,
                         apply_tissue_mask: bool = True,
                         apply_stain_norm: bool = True) -> Tuple[np.ndarray, dict]:
        """
        Complete 7-step preprocessing pipeline
        Returns: (l2_normalized_features, metadata)
        """
        metadata = {
            'original_size': image.size,
            'source_um_per_pixel': source_um_per_pixel,
            'target_um_per_pixel': self.target_um_per_pixel,
            'pipeline_steps': []
        }
        
        print(f"\n{'='*60}")
        print(f"üî¨ PATHOLOGY PREPROCESSING PIPELINE")
        print(f"{'='*60}")
        
        try:
            # Step 1: Scale normalization
            print("1Ô∏è‚É£ Scale normalization...")
            scaled_image = self.scale_normalize(image, source_um_per_pixel)
            metadata['pipeline_steps'].append('scale_normalization')
            metadata['scale_factor'] = source_um_per_pixel / self.target_um_per_pixel
            
            # Step 2: Tissue masking
            if apply_tissue_mask:
                print("2Ô∏è‚É£ Tissue masking...")
                masked_image, tissue_mask = self.tissue_mask(scaled_image)
                metadata['pipeline_steps'].append('tissue_masking')
                metadata['tissue_percentage'] = (tissue_mask > 0).sum() / tissue_mask.size * 100
            else:
                masked_image = scaled_image
                print("2Ô∏è‚É£ Tissue masking skipped")
            
            # Step 3: Stain normalization
            if apply_stain_norm:
                print("3Ô∏è‚É£ Stain normalization...")
                stain_normalized = self.stain_normalize(masked_image)
                metadata['pipeline_steps'].append('stain_normalization')
            else:
                stain_normalized = masked_image
                print("3Ô∏è‚É£ Stain normalization skipped")
            
            # Step 4: Resize to 224x224
            print("4Ô∏è‚É£ Resize to 224x224...")
            resized = self.resize_to_model_input(stain_normalized)
            metadata['pipeline_steps'].append('resize_224x224')
            metadata['final_size'] = resized.size
            
            # Step 5: ImageNet normalization
            print("5Ô∏è‚É£ ImageNet normalization...")
            tensor = self.imagenet_normalize(resized)
            metadata['pipeline_steps'].append('imagenet_normalization')
            
            # Step 6: GigaPath feature extraction
            print("6Ô∏è‚É£ GigaPath feature extraction...")
            features = self.extract_gigapath_features(tensor, gigapath_model)
            metadata['pipeline_steps'].append('gigapath_extraction')
            metadata['feature_dimension'] = features.shape[0]
            
            # Step 7: L2 normalization
            print("7Ô∏è‚É£ L2 normalization...")
            l2_features = self.l2_normalize_features(features)
            metadata['pipeline_steps'].append('l2_normalization')
            
            print(f"‚úÖ Pipeline complete: {len(metadata['pipeline_steps'])} steps")
            print(f"{'='*60}\n")
            
            return l2_features, metadata
            
        except Exception as e:
            print(f"‚ùå Pipeline failed at step: {e}")
            import traceback
            traceback.print_exc()
            raise

def get_dataset_um_per_pixel(dataset_name: str) -> float:
    """Get Œºm/pixel for known datasets"""
    return DATASET_METADATA.get(dataset_name, {}).get('um_per_pixel', TARGET_UM_PER_PIXEL)

def detect_image_scale(image: Image.Image, filename: str = "") -> float:
    """
    Detect or estimate Œºm/pixel from image
    This is a placeholder - in production, would use DICOM metadata or filename patterns
    """
    # Simple heuristics based on filename patterns
    filename_lower = filename.lower()
    
    if 'bach' in filename_lower:
        return DATASET_METADATA['bach']['um_per_pixel']
    elif any(x in filename_lower for x in ['breakhis', 'sob_']):
        return DATASET_METADATA['breakhis']['um_per_pixel']
    else:
        # Default assumption for unknown images
        print(f"‚ö†Ô∏è Unknown image source, assuming {TARGET_UM_PER_PIXEL} Œºm/pixel")
        return TARGET_UM_PER_PIXEL

# Global preprocessor instance
preprocessor = PathologyPreprocessor()

def setup_stain_reference_from_cache():
    """Setup stain normalization reference from training data"""
    if not STAIN_TOOLS_AVAILABLE:
        return False
    
    try:
        # Load a representative H&E image from cache for reference
        # This would ideally be done during cache creation
        print("üé® Setting up stain normalization reference...")
        
        # For now, we'll set it up when the first image is processed
        # In production, should use a high-quality reference image
        return True
        
    except Exception as e:
        print(f"‚ö†Ô∏è Failed to setup stain reference: {e}")
        return False

if __name__ == "__main__":
    # Test the preprocessing pipeline
    print("üß™ Testing preprocessing pipeline...")
    
    # Create a test image
    test_image = Image.new('RGB', (512, 512), color=(200, 150, 200))
    
    # Test scale normalization
    scaled = preprocessor.scale_normalize(test_image, 0.467)  # BreakHis ‚Üí BACH scale
    
    # Test tissue masking
    masked, mask = preprocessor.tissue_mask(scaled)
    
    print("‚úÖ Preprocessing pipeline components tested successfully!")